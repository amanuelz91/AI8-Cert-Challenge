# =============================================================================
# RAG System Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# Required variables are marked with [REQUIRED]

# =============================================================================
# API KEYS [REQUIRED]
# =============================================================================
# OpenAI API Key - Required for LLM and embeddings
OPENAI_API_KEY=your_openai_api_key_here
# Optional API Keys
COHERE_API_KEY=your_cohere_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here

# =============================================================================
# DATABASE CONFIGURATION (Qdrant Vector Database)
# =============================================================================
# Qdrant server URL
QDRANT_URL=https://your-qdrant-instance.us-east-1-1.aws.cloud.qdrant.io

# Qdrant API key (optional, for cloud instances)
QDRANT_API_KEY=your_qdrant_api_key_here

# Collection name for storing documents
QDRANT_COLLECTION=rag_documents

# Vector embedding size (1536 for OpenAI text-embedding-3-small)
VECTOR_SIZE=1536

# =============================================================================
# EMBEDDING MODEL CONFIGURATION
# =============================================================================
# OpenAI embedding model to use
EMBEDDING_MODEL=text-embedding-3-small

# Batch size for embedding processing
EMBEDDING_BATCH_SIZE=100

# Enable embedding cache
EMBEDDING_CACHE=true

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# OpenAI model to use for text generation
LLM_MODEL=gpt-4o-mini

# Temperature for text generation (0.0 = deterministic)
LLM_TEMPERATURE=0.0

# Maximum tokens in response
LLM_MAX_TOKENS=1000

# Timeout for LLM requests (seconds)
LLM_TIMEOUT=120

# =============================================================================
# RETRIEVAL CONFIGURATION
# =============================================================================
# Number of documents to retrieve by default
RETRIEVAL_K=5

# Similarity threshold for document retrieval
SIMILARITY_THRESHOLD=0.7

# Maximum context length for retrieved documents
MAX_CONTEXT_LENGTH=4000

# =============================================================================
# DATA PROCESSING CONFIGURATION
# =============================================================================
# Size of document chunks
CHUNK_SIZE=750

# Overlap between document chunks
CHUNK_OVERLAP=100

# Path to data folder containing PDF documents
DATA_FOLDER=./src/data

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Optional log file path
LOG_FILE=

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Set to true for development mode
DEBUG=false

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# Optional API Keys
LANGSMITH_API_KEY=your_langsmith_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
