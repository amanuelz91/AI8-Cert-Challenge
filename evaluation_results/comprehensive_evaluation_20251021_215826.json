{
  "timestamp": "2025-10-21T21:58:26.462614",
  "config": {
    "testset_size": 10,
    "langsmith_project": "rag-evaluation",
    "langsmith_tracing": true
  },
  "dataset_info": {
    "filepath": "evaluation_results/evaluation_dataset_20251021_215155.csv",
    "num_samples": 12
  },
  "evaluation_results": {
    "individual_results": {
      "naive": {
        "error": "Failed to evaluate method naive: Failed to generate responses for method naive: ragas.dataset_schema.SingleTurnSample() argument after ** must be a mapping, not str",
        "method": "naive",
        "timestamp": "2025-10-21 21:52:31.183173"
      },
      "semantic": {
        "error": "Failed to evaluate method semantic: Failed to generate responses for method semantic: ragas.dataset_schema.SingleTurnSample() argument after ** must be a mapping, not str",
        "method": "semantic",
        "timestamp": "2025-10-21 21:53:03.823716"
      },
      "tool": {
        "error": "Failed to evaluate method tool: Failed to generate responses for method tool: ragas.dataset_schema.SingleTurnSample() argument after ** must be a mapping, not str",
        "method": "tool",
        "timestamp": "2025-10-21 21:57:10.298577"
      },
      "hybrid": {
        "error": "Failed to evaluate method hybrid: Failed to generate responses for method hybrid: ragas.dataset_schema.SingleTurnSample() argument after ** must be a mapping, not str",
        "method": "hybrid",
        "timestamp": "2025-10-21 21:58:26.461648"
      },
      "production": {
        "error": "Failed to evaluate method production: Failed to generate responses for method production: Query failed: At key 'question': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
        "method": "production",
        "timestamp": "2025-10-21 21:56:02.423779"
      }
    },
    "comparison": {
      "method_rankings": [],
      "best_method": null,
      "score_differences": {},
      "metric_comparisons": {}
    },
    "timestamp": "2025-10-21 21:58:26.461976",
    "methods_evaluated": [
      "naive",
      "semantic",
      "tool",
      "hybrid",
      "production",
      "tool",
      "hybrid"
    ],
    "total_methods": 7
  }
}